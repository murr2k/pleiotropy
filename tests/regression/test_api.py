"""
Comprehensive API Regression Test Suite
Tests all API endpoints with various payloads, security, and edge cases.

Memory Namespace: swarm-regression-1752301224
"""

import pytest
import asyncio
import json
import time
import websockets
from datetime import datetime, timedelta
from typing import Dict, Any, List
from faker import Faker
from httpx import AsyncClient
from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession
import jwt

# Import your app and database setup
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '../../trial_database/api'))

from app.main import app
from app.db.database import get_db, engine
from app.core.config import settings
from app.models.database import Agent, Trial, Result, Progress

fake = Faker()

# Test configuration
API_BASE_URL = "http://testserver"
WS_BASE_URL = "ws://testserver"

# Test data storage for memory namespace
TEST_FINDINGS = {
    "api_bugs": [],
    "security_vulnerabilities": [],
    "performance_issues": [],
    "edge_case_failures": []
}

class APITestConfig:
    """Configuration for API regression tests"""
    MAX_BATCH_SIZE = 1000
    LOAD_TEST_CONNECTIONS = 50
    RATE_LIMIT_REQUESTS = 100
    TIMEOUT_SECONDS = 30
    

@pytest.fixture(scope="session")
async def db_session():
    """Database session fixture for testing"""
    async with AsyncSession(engine) as session:
        yield session

@pytest.fixture(scope="session") 
async def test_client():
    """HTTP client fixture"""
    async with AsyncClient(app=app, base_url=API_BASE_URL) as client:
        yield client

@pytest.fixture(scope="session")
async def admin_agent(db_session: AsyncSession):
    """Create admin agent for testing"""
    admin_data = {
        "name": "test_admin_agent",
        "password": "test_password_123",
        "role": "coordinator",
        "capabilities": ["admin", "validate", "coordinate"],
        "active": True
    }
    
    async with AsyncClient(app=app, base_url=API_BASE_URL) as client:
        response = await client.post("/api/v1/agents/register", json=admin_data)
        assert response.status_code == 201
        agent = response.json()
        
        # Login to get token
        login_response = await client.post(
            "/api/v1/agents/login",
            data={"username": admin_data["name"], "password": admin_data["password"]}
        )
        assert login_response.status_code == 200
        login_data = login_response.json()
        
        return {
            "agent": agent,
            "token": login_data["access_token"],
            "headers": {"Authorization": f"Bearer {login_data['access_token']}"}
        }

@pytest.fixture(scope="session")
async def test_trial(test_client: AsyncClient, admin_agent: dict):
    """Create test trial for testing"""
    trial_data = {
        "name": "Test Trial for API Regression",
        "description": "Automated test trial for comprehensive API testing",
        "organism": "E. coli K-12",
        "genome_file": "/data/test_ecoli_genome.fasta",
        "parameters": {
            "window_size": 1000,
            "min_confidence": 0.7,
            "trait_count": 5,
            "analysis_depth": "comprehensive"
        },
        "created_by": admin_agent["agent"]["id"]
    }
    
    response = await test_client.post(
        "/api/v1/trials/",
        json=trial_data,
        headers=admin_agent["headers"]
    )
    assert response.status_code == 201
    return response.json()


class TestAgentsAPI:
    """Test Agents API endpoints"""
    
    @pytest.mark.asyncio
    async def test_agent_registration_valid(self, test_client: AsyncClient):
        """Test valid agent registration"""
        agent_data = {
            "name": fake.user_name(),
            "password": fake.password(length=12),
            "role": "analyzer",
            "capabilities": ["sequence_analysis", "trait_extraction"],
            "active": True
        }
        
        response = await test_client.post("/api/v1/agents/register", json=agent_data)
        assert response.status_code == 201
        
        agent = response.json()
        assert agent["name"] == agent_data["name"]
        assert agent["role"] == agent_data["role"]
        assert "hashed_password" not in agent  # Password should not be returned
        
    @pytest.mark.asyncio
    async def test_agent_registration_duplicate_name(self, test_client: AsyncClient):
        """Test duplicate agent name registration"""
        agent_data = {
            "name": "duplicate_test_agent",
            "password": "test_password_123",
            "role": "analyzer"
        }
        
        # Register first agent
        response1 = await test_client.post("/api/v1/agents/register", json=agent_data)
        assert response1.status_code == 201
        
        # Attempt to register duplicate
        response2 = await test_client.post("/api/v1/agents/register", json=agent_data)
        assert response2.status_code == 400
        assert "already registered" in response2.json()["detail"]
        
    @pytest.mark.asyncio
    async def test_agent_registration_invalid_data(self, test_client: AsyncClient):
        """Test agent registration with invalid data"""
        test_cases = [
            # Missing required fields
            {"name": "test", "role": "analyzer"},  # Missing password
            {"password": "test123", "role": "analyzer"},  # Missing name
            {"name": "test", "password": "test123"},  # Missing role
            
            # Invalid field values
            {"name": "", "password": "test123", "role": "analyzer"},  # Empty name
            {"name": "test", "password": "123", "role": "analyzer"},  # Short password
            {"name": "test", "password": "test123", "role": "invalid_role"},  # Invalid role
            
            # Injection attempts
            {"name": "'; DROP TABLE agents; --", "password": "test123", "role": "analyzer"},
            {"name": "<script>alert('xss')</script>", "password": "test123", "role": "analyzer"}
        ]
        
        for i, invalid_data in enumerate(test_cases):
            response = await test_client.post("/api/v1/agents/register", json=invalid_data)
            assert response.status_code in [400, 422], f"Test case {i}: {invalid_data}"
            
            if response.status_code == 200:
                TEST_FINDINGS["security_vulnerabilities"].append({
                    "endpoint": "/api/v1/agents/register",
                    "vulnerability": "Accepts invalid/malicious input",
                    "payload": invalid_data,
                    "severity": "high"
                })
    
    @pytest.mark.asyncio
    async def test_agent_login_valid(self, test_client: AsyncClient):
        """Test valid agent login"""
        # First register an agent
        agent_data = {
            "name": "login_test_agent",
            "password": "secure_password_123",
            "role": "analyzer"
        }
        
        reg_response = await test_client.post("/api/v1/agents/register", json=agent_data)
        assert reg_response.status_code == 201
        
        # Test login
        login_response = await test_client.post(
            "/api/v1/agents/login",
            data={"username": agent_data["name"], "password": agent_data["password"]}
        )
        assert login_response.status_code == 200
        
        login_data = login_response.json()
        assert "access_token" in login_data
        assert login_data["token_type"] == "bearer"
        assert login_data["name"] == agent_data["name"]
        
        # Verify token is valid JWT
        try:
            payload = jwt.decode(
                login_data["access_token"], 
                settings.SECRET_KEY, 
                algorithms=[settings.ALGORITHM]
            )
            assert "sub" in payload
            assert "exp" in payload
        except jwt.JWTError:
            pytest.fail("Invalid JWT token returned")
    
    @pytest.mark.asyncio
    async def test_agent_login_invalid_credentials(self, test_client: AsyncClient):
        """Test login with invalid credentials"""
        test_cases = [
            {"username": "nonexistent_agent", "password": "any_password"},
            {"username": "login_test_agent", "password": "wrong_password"},
            {"username": "", "password": "password"},
            {"username": "agent", "password": ""},
            
            # SQL injection attempts
            {"username": "admin'; --", "password": "password"},
            {"username": "admin", "password": "' OR '1'='1"},
        ]
        
        for invalid_creds in test_cases:
            response = await test_client.post("/api/v1/agents/login", data=invalid_creds)
            assert response.status_code == 401
            
    @pytest.mark.asyncio
    async def test_get_current_agent_info(self, test_client: AsyncClient, admin_agent: dict):
        """Test getting current agent information"""
        response = await test_client.get(
            "/api/v1/agents/me",
            headers=admin_agent["headers"]
        )
        assert response.status_code == 200
        
        agent_info = response.json()
        assert agent_info["id"] == admin_agent["agent"]["id"]
        assert agent_info["name"] == admin_agent["agent"]["name"]
        assert "hashed_password" not in agent_info
    
    @pytest.mark.asyncio
    async def test_unauthorized_access(self, test_client: AsyncClient):
        """Test unauthorized access to protected endpoints"""
        protected_endpoints = [
            ("GET", "/api/v1/agents/me"),
            ("GET", "/api/v1/agents/"),
            ("PATCH", "/api/v1/agents/1"),
            ("DELETE", "/api/v1/agents/1"),
        ]
        
        for method, endpoint in protected_endpoints:
            if method == "GET":
                response = await test_client.get(endpoint)
            elif method == "PATCH":
                response = await test_client.patch(endpoint, json={})
            elif method == "DELETE":
                response = await test_client.delete(endpoint)
                
            assert response.status_code == 401, f"Endpoint {method} {endpoint} should require authentication"
    
    @pytest.mark.asyncio
    async def test_role_based_access_control(self, test_client: AsyncClient, admin_agent: dict):
        """Test role-based access control"""
        # Create a regular agent
        regular_agent_data = {
            "name": "regular_agent_rbac",
            "password": "password123",
            "role": "analyzer"
        }
        
        reg_response = await test_client.post("/api/v1/agents/register", json=regular_agent_data)
        assert reg_response.status_code == 201
        
        # Login regular agent
        login_response = await test_client.post(
            "/api/v1/agents/login",
            data={"username": regular_agent_data["name"], "password": regular_agent_data["password"]}
        )
        assert login_response.status_code == 200
        regular_token = login_response.json()["access_token"]
        regular_headers = {"Authorization": f"Bearer {regular_token}"}
        
        # Test coordinator-only endpoints with regular agent
        coordinator_endpoints = [
            ("GET", "/api/v1/agents/"),
            ("DELETE", "/api/v1/agents/1"),
        ]
        
        for method, endpoint in coordinator_endpoints:
            if method == "GET":
                response = await test_client.get(endpoint, headers=regular_headers)
            elif method == "DELETE":
                response = await test_client.delete(endpoint, headers=regular_headers)
                
            assert response.status_code == 403, f"Regular agent should not access {method} {endpoint}"


class TestTrialsAPI:
    """Test Trials API endpoints"""
    
    @pytest.mark.asyncio
    async def test_create_trial_valid(self, test_client: AsyncClient, admin_agent: dict):
        """Test creating a valid trial"""
        trial_data = {
            "name": f"Test Trial {fake.uuid4()}",
            "description": "Automated test trial",
            "organism": "E. coli K-12",
            "genome_file": "/data/test_genome.fasta",
            "parameters": {
                "window_size": 1000,
                "min_confidence": 0.8,
                "trait_count": 3
            },
            "created_by": admin_agent["agent"]["id"]
        }
        
        response = await test_client.post(
            "/api/v1/trials/",
            json=trial_data,
            headers=admin_agent["headers"]
        )
        assert response.status_code == 201
        
        trial = response.json()
        assert trial["name"] == trial_data["name"]
        assert trial["status"] == "pending"
        assert trial["created_by"] == admin_agent["agent"]["id"]
    
    @pytest.mark.asyncio
    async def test_create_trial_invalid_parameters(self, test_client: AsyncClient, admin_agent: dict):
        """Test creating trial with invalid parameters"""
        invalid_trials = [
            # Missing required parameters
            {
                "name": "Invalid Trial 1",
                "organism": "E. coli",
                "genome_file": "/data/test.fasta",
                "parameters": {
                    "window_size": 1000,
                    "min_confidence": 0.8
                    # Missing trait_count
                },
                "created_by": admin_agent["agent"]["id"]
            },
            
            # Invalid parameter values
            {
                "name": "Invalid Trial 2",
                "organism": "E. coli",
                "genome_file": "/data/test.fasta",
                "parameters": {
                    "window_size": -1,  # Invalid negative value
                    "min_confidence": 1.5,  # Invalid > 1.0
                    "trait_count": 0  # Invalid zero
                },
                "created_by": admin_agent["agent"]["id"]
            }
        ]
        
        for invalid_trial in invalid_trials:
            response = await test_client.post(
                "/api/v1/trials/",
                json=invalid_trial,
                headers=admin_agent["headers"]
            )
            assert response.status_code in [400, 422]
    
    @pytest.mark.asyncio
    async def test_list_trials_pagination(self, test_client: AsyncClient, admin_agent: dict):
        """Test trials listing with pagination"""
        # Create multiple trials for pagination testing
        for i in range(25):
            trial_data = {
                "name": f"Pagination Test Trial {i}",
                "organism": "E. coli",
                "genome_file": f"/data/test_{i}.fasta",
                "parameters": {
                    "window_size": 1000,
                    "min_confidence": 0.7,
                    "trait_count": 2
                },
                "created_by": admin_agent["agent"]["id"]
            }
            
            response = await test_client.post(
                "/api/v1/trials/",
                json=trial_data,
                headers=admin_agent["headers"]
            )
            assert response.status_code == 201
        
        # Test pagination
        response = await test_client.get("/api/v1/trials/?page=1&page_size=10")
        assert response.status_code == 200
        
        data = response.json()
        assert "items" in data
        assert "total" in data
        assert "page" in data
        assert "page_size" in data
        assert "pages" in data
        assert len(data["items"]) <= 10
        assert data["page"] == 1
        assert data["page_size"] == 10
        
        # Test filtering
        filter_response = await test_client.get("/api/v1/trials/?status=pending&organism=E.%20coli")
        assert filter_response.status_code == 200
    
    @pytest.mark.asyncio
    async def test_get_trial_by_id(self, test_client: AsyncClient, test_trial: dict):
        """Test getting specific trial by ID"""
        response = await test_client.get(f"/api/v1/trials/{test_trial['id']}")
        assert response.status_code == 200
        
        trial = response.json()
        assert trial["id"] == test_trial["id"]
        assert trial["name"] == test_trial["name"]
    
    @pytest.mark.asyncio
    async def test_get_nonexistent_trial(self, test_client: AsyncClient):
        """Test getting non-existent trial"""
        response = await test_client.get("/api/v1/trials/999999")
        assert response.status_code == 404
        assert "not found" in response.json()["detail"]
    
    @pytest.mark.asyncio
    async def test_update_trial(self, test_client: AsyncClient, admin_agent: dict, test_trial: dict):
        """Test updating trial"""
        update_data = {
            "status": "running",
            "description": "Updated description for testing"
        }
        
        response = await test_client.patch(
            f"/api/v1/trials/{test_trial['id']}",
            json=update_data,
            headers=admin_agent["headers"]
        )
        assert response.status_code == 200
        
        updated_trial = response.json()
        assert updated_trial["status"] == "running"
        assert updated_trial["description"] == update_data["description"]
        assert updated_trial["started_at"] is not None
    
    @pytest.mark.asyncio
    async def test_delete_trial_restrictions(self, test_client: AsyncClient, admin_agent: dict):
        """Test trial deletion restrictions"""
        # Create a trial and set it to running
        trial_data = {
            "name": "Delete Test Trial",
            "organism": "E. coli",
            "genome_file": "/data/test.fasta",
            "parameters": {
                "window_size": 1000,
                "min_confidence": 0.7,
                "trait_count": 2
            },
            "created_by": admin_agent["agent"]["id"]
        }
        
        create_response = await test_client.post(
            "/api/v1/trials/",
            json=trial_data,
            headers=admin_agent["headers"]
        )
        assert create_response.status_code == 201
        trial = create_response.json()
        
        # Update to running status
        await test_client.patch(
            f"/api/v1/trials/{trial['id']}",
            json={"status": "running"},
            headers=admin_agent["headers"]
        )
        
        # Should not be able to delete running trial
        delete_response = await test_client.delete(
            f"/api/v1/trials/{trial['id']}",
            headers=admin_agent["headers"]
        )
        assert delete_response.status_code == 400
        assert "Can only delete pending or failed trials" in delete_response.json()["detail"]


class TestResultsAPI:
    """Test Results API endpoints"""
    
    @pytest.mark.asyncio
    async def test_create_result_valid(self, test_client: AsyncClient, admin_agent: dict, test_trial: dict):
        """Test creating a valid result"""
        result_data = {
            "trial_id": test_trial["id"],
            "gene_id": "test_gene_001",
            "traits": ["metabolism", "stress_response"],
            "confidence_scores": {
                "metabolism": 0.85,
                "stress_response": 0.72
            },
            "codon_usage_bias": {
                "TTT": 0.15,
                "TTC": 0.85,
                "TTA": 0.20,
                "TTG": 0.80
            },
            "regulatory_context": {
                "promoter_strength": 0.6,
                "enhancers": ["enhancer_1", "enhancer_3"]
            }
        }
        
        response = await test_client.post(
            "/api/v1/results/",
            json=result_data,
            headers=admin_agent["headers"]
        )
        assert response.status_code == 201
        
        result = response.json()
        assert result["trial_id"] == test_trial["id"]
        assert result["gene_id"] == "test_gene_001"
        assert result["traits"] == ["metabolism", "stress_response"]
        assert result["validated"] == False
    
    @pytest.mark.asyncio
    async def test_create_result_nonexistent_trial(self, test_client: AsyncClient, admin_agent: dict):
        """Test creating result for non-existent trial"""
        result_data = {
            "trial_id": 999999,  # Non-existent trial
            "gene_id": "test_gene_002",
            "traits": ["metabolism"],
            "confidence_scores": {"metabolism": 0.8},
            "codon_usage_bias": {"TTT": 0.5, "TTC": 0.5}
        }
        
        response = await test_client.post(
            "/api/v1/results/",
            json=result_data,
            headers=admin_agent["headers"]
        )
        assert response.status_code == 404
        assert "not found" in response.json()["detail"]
    
    @pytest.mark.asyncio
    async def test_list_results_filtering(self, test_client: AsyncClient, admin_agent: dict, test_trial: dict):
        """Test results listing with filtering"""
        # Create multiple results with different characteristics
        results_data = [
            {
                "trial_id": test_trial["id"],
                "gene_id": "gene_filter_001",
                "traits": ["metabolism"],
                "confidence_scores": {"metabolism": 0.9},
                "codon_usage_bias": {"TTT": 0.5, "TTC": 0.5}
            },
            {
                "trial_id": test_trial["id"],
                "gene_id": "gene_filter_002",
                "traits": ["stress_response"],
                "confidence_scores": {"stress_response": 0.6},
                "codon_usage_bias": {"TTT": 0.3, "TTC": 0.7}
            }
        ]
        
        for result_data in results_data:
            response = await test_client.post(
                "/api/v1/results/",
                json=result_data,
                headers=admin_agent["headers"]
            )
            assert response.status_code == 201
        
        # Test filtering by trial_id
        response = await test_client.get(f"/api/v1/results/?trial_id={test_trial['id']}")
        assert response.status_code == 200
        
        # Test filtering by gene_id
        response = await test_client.get("/api/v1/results/?gene_id=gene_filter_001")
        assert response.status_code == 200
        data = response.json()
        if data["items"]:
            assert all(item["gene_id"] == "gene_filter_001" for item in data["items"])
        
        # Test filtering by minimum confidence
        response = await test_client.get("/api/v1/results/?min_confidence=0.8")
        assert response.status_code == 200
    
    @pytest.mark.asyncio
    async def test_validate_result(self, test_client: AsyncClient, admin_agent: dict, test_trial: dict):
        """Test result validation"""
        # Create a result first
        result_data = {
            "trial_id": test_trial["id"],
            "gene_id": "validation_test_gene",
            "traits": ["metabolism"],
            "confidence_scores": {"metabolism": 0.8},
            "codon_usage_bias": {"TTT": 0.4, "TTC": 0.6}
        }
        
        create_response = await test_client.post(
            "/api/v1/results/",
            json=result_data,
            headers=admin_agent["headers"]
        )
        assert create_response.status_code == 201
        result = create_response.json()
        
        # Validate the result
        validation_data = {
            "validated": True,
            "validation_notes": "Manually verified against known database"
        }
        
        response = await test_client.patch(
            f"/api/v1/results/{result['id']}",
            json=validation_data,
            headers=admin_agent["headers"]
        )
        assert response.status_code == 200
        
        validated_result = response.json()
        assert validated_result["validated"] == True
        assert validated_result["validation_notes"] == validation_data["validation_notes"]
        assert validated_result["validated_by"] == admin_agent["agent"]["id"]
        assert validated_result["validated_at"] is not None


class TestProgressAPI:
    """Test Progress API endpoints"""
    
    @pytest.mark.asyncio
    async def test_create_progress_update(self, test_client: AsyncClient, admin_agent: dict, test_trial: dict):
        """Test creating progress update"""
        progress_data = {
            "trial_id": test_trial["id"],
            "stage": "sequence_parsing",
            "progress_percentage": 25.5,
            "current_task": "Parsing genome file",
            "genes_processed": 250,
            "total_genes": 1000
        }
        
        response = await test_client.post(
            "/api/v1/progress/",
            json=progress_data,
            headers=admin_agent["headers"]
        )
        assert response.status_code == 201
        
        progress = response.json()
        assert progress["trial_id"] == test_trial["id"]
        assert progress["progress_percentage"] == 25.5
        assert progress["genes_processed"] == 250
    
    @pytest.mark.asyncio
    async def test_get_trial_progress(self, test_client: AsyncClient, test_trial: dict):
        """Test getting progress for a trial"""
        response = await test_client.get(f"/api/v1/progress/trial/{test_trial['id']}")
        assert response.status_code == 200
        
        progress_list = response.json()
        assert isinstance(progress_list, list)
    
    @pytest.mark.asyncio
    async def test_get_latest_progress(self, test_client: AsyncClient, admin_agent: dict, test_trial: dict):
        """Test getting latest progress update"""
        # Create a progress update
        progress_data = {
            "trial_id": test_trial["id"],
            "stage": "trait_analysis",
            "progress_percentage": 75.0,
            "current_task": "Analyzing trait patterns",
            "genes_processed": 750,
            "total_genes": 1000
        }
        
        await test_client.post(
            "/api/v1/progress/",
            json=progress_data,
            headers=admin_agent["headers"]
        )
        
        # Get latest progress
        response = await test_client.get(f"/api/v1/progress/trial/{test_trial['id']}/latest")
        
        if response.status_code == 200:
            latest = response.json()
            assert latest["trial_id"] == test_trial["id"]
        elif response.status_code == 404:
            # This is acceptable if no progress updates exist yet
            pass
        else:
            pytest.fail(f"Unexpected status code: {response.status_code}")


class TestBatchOperations:
    """Test batch operations performance and functionality"""
    
    @pytest.mark.asyncio
    async def test_batch_create_trials(self, test_client: AsyncClient, admin_agent: dict):
        """Test batch trial creation"""
        batch_data = {
            "operation": "create",
            "items": []
        }
        
        # Create 10 trials in batch
        for i in range(10):
            trial_item = {
                "name": f"Batch Trial {i}",
                "organism": "E. coli",
                "genome_file": f"/data/batch_{i}.fasta",
                "parameters": {
                    "window_size": 1000,
                    "min_confidence": 0.7,
                    "trait_count": 3
                },
                "created_by": admin_agent["agent"]["id"]
            }
            batch_data["items"].append(trial_item)
        
        start_time = time.time()
        response = await test_client.post(
            "/api/v1/trials/batch",
            json=batch_data,
            headers=admin_agent["headers"]
        )
        end_time = time.time()
        
        assert response.status_code == 200
        
        result = response.json()
        assert result["success_count"] == 10
        assert result["error_count"] == 0
        assert len(result["results"]) == 10
        
        # Performance check - batch should be faster than individual requests
        batch_time = end_time - start_time
        if batch_time > 5.0:  # 5 seconds threshold
            TEST_FINDINGS["performance_issues"].append({
                "operation": "batch_create_trials",
                "time_taken": batch_time,
                "items_count": 10,
                "issue": "Batch operation taking too long"
            })
    
    @pytest.mark.asyncio
    async def test_batch_create_results(self, test_client: AsyncClient, admin_agent: dict, test_trial: dict):
        """Test batch result creation"""
        batch_data = {
            "operation": "create",
            "items": []
        }
        
        # Create 50 results in batch
        for i in range(50):
            result_item = {
                "trial_id": test_trial["id"],
                "gene_id": f"batch_gene_{i:03d}",
                "traits": ["metabolism", "stress_response"][(i % 2):((i % 2) + 1)],
                "confidence_scores": {
                    "metabolism": 0.7 + (i % 30) / 100,
                    "stress_response": 0.6 + (i % 40) / 100
                },
                "codon_usage_bias": {
                    "TTT": 0.3 + (i % 20) / 100,
                    "TTC": 0.7 - (i % 20) / 100
                }
            }
            batch_data["items"].append(result_item)
        
        start_time = time.time()
        response = await test_client.post(
            "/api/v1/results/batch",
            json=batch_data,
            headers=admin_agent["headers"]
        )
        end_time = time.time()
        
        assert response.status_code == 200
        
        result = response.json()
        assert result["success_count"] == 50
        
        # Performance tracking
        batch_time = end_time - start_time
        throughput = 50 / batch_time if batch_time > 0 else float('inf')
        
        if throughput < 10:  # Less than 10 items/second
            TEST_FINDINGS["performance_issues"].append({
                "operation": "batch_create_results",
                "throughput": throughput,
                "time_taken": batch_time,
                "items_count": 50,
                "issue": "Low throughput for batch operations"
            })
    
    @pytest.mark.asyncio
    async def test_batch_size_limits(self, test_client: AsyncClient, admin_agent: dict):
        """Test batch size limits and error handling"""
        # Test maximum batch size
        large_batch = {
            "operation": "create",
            "items": [
                {
                    "name": f"Large Batch Trial {i}",
                    "organism": "E. coli",
                    "genome_file": f"/data/large_{i}.fasta",
                    "parameters": {
                        "window_size": 1000,
                        "min_confidence": 0.7,
                        "trait_count": 2
                    },
                    "created_by": admin_agent["agent"]["id"]
                }
                for i in range(1001)  # Exceed max batch size
            ]
        }
        
        response = await test_client.post(
            "/api/v1/trials/batch",
            json=large_batch,
            headers=admin_agent["headers"]
        )
        assert response.status_code == 422  # Should reject oversized batch


class TestWebSocketFunctionality:
    """Test WebSocket functionality and load testing"""
    
    @pytest.mark.asyncio
    async def test_websocket_connection(self):
        """Test basic WebSocket connection"""
        try:
            uri = f"{WS_BASE_URL}/ws/connect?client_id=test_client_1&agent_name=test_agent"
            
            async with websockets.connect(uri) as websocket:
                # Send ping message
                ping_message = {"type": "ping"}
                await websocket.send(json.dumps(ping_message))
                
                # Receive pong response
                response = await asyncio.wait_for(websocket.recv(), timeout=5.0)
                response_data = json.loads(response)
                
                assert response_data["type"] == "pong"
                
        except Exception as e:
            TEST_FINDINGS["api_bugs"].append({
                "component": "WebSocket",
                "issue": "WebSocket connection failed",
                "error": str(e),
                "severity": "high"
            })
    
    @pytest.mark.asyncio
    async def test_websocket_subscription(self, test_trial: dict):
        """Test WebSocket trial subscription"""
        try:
            uri = f"{WS_BASE_URL}/ws/connect?client_id=test_sub_client&agent_name=test_agent"
            
            async with websockets.connect(uri) as websocket:
                # Subscribe to trial updates
                subscribe_message = {
                    "type": "subscribe",
                    "trial_id": test_trial["id"]
                }
                await websocket.send(json.dumps(subscribe_message))
                
                # Wait for subscription confirmation
                response = await asyncio.wait_for(websocket.recv(), timeout=5.0)
                response_data = json.loads(response)
                
                assert response_data["type"] == "subscription_confirmed"
                assert response_data["data"]["trial_id"] == test_trial["id"]
                
        except Exception as e:
            TEST_FINDINGS["api_bugs"].append({
                "component": "WebSocket",
                "issue": "WebSocket subscription failed",
                "error": str(e),
                "trial_id": test_trial["id"]
            })
    
    @pytest.mark.asyncio
    async def test_websocket_load(self):
        """Test WebSocket under load"""
        connections = []
        connection_count = min(APITestConfig.LOAD_TEST_CONNECTIONS, 20)  # Limit for testing
        
        try:
            # Create multiple connections
            for i in range(connection_count):
                uri = f"{WS_BASE_URL}/ws/connect?client_id=load_test_{i}&agent_name=load_agent_{i}"
                websocket = await websockets.connect(uri)
                connections.append(websocket)
            
            # Send messages from all connections simultaneously
            start_time = time.time()
            tasks = []
            
            for i, websocket in enumerate(connections):
                message = {"type": "ping", "client_id": f"load_test_{i}"}
                task = websocket.send(json.dumps(message))
                tasks.append(task)
            
            await asyncio.gather(*tasks)
            end_time = time.time()
            
            # Check response time
            response_time = end_time - start_time
            if response_time > 2.0:  # 2 second threshold
                TEST_FINDINGS["performance_issues"].append({
                    "component": "WebSocket",
                    "operation": "load_test",
                    "connections": connection_count,
                    "response_time": response_time,
                    "issue": "High response time under load"
                })
            
        except Exception as e:
            TEST_FINDINGS["api_bugs"].append({
                "component": "WebSocket",
                "issue": "WebSocket load test failed",
                "error": str(e),
                "connections_attempted": connection_count
            })
        
        finally:
            # Clean up connections
            for websocket in connections:
                try:
                    await websocket.close()
                except:
                    pass


class TestSecurityAndValidation:
    """Test security vulnerabilities and input validation"""
    
    @pytest.mark.asyncio
    async def test_sql_injection_attempts(self, test_client: AsyncClient, admin_agent: dict):
        """Test SQL injection protection"""
        sql_injection_payloads = [
            "'; DROP TABLE agents; --",
            "' OR '1'='1",
            "'; INSERT INTO agents (name) VALUES ('hacker'); --",
            "' UNION SELECT * FROM agents --",
            "1'; UPDATE agents SET role='coordinator' WHERE id=1; --"
        ]
        
        for payload in sql_injection_payloads:
            # Test in various endpoints
            endpoints_to_test = [
                ("/api/v1/trials/", {"name": payload, "organism": "E. coli", "genome_file": "/test", "parameters": {"window_size": 1000, "min_confidence": 0.7, "trait_count": 2}, "created_by": admin_agent["agent"]["id"]}),
                ("/api/v1/results/", {"trial_id": 1, "gene_id": payload, "traits": ["test"], "confidence_scores": {"test": 0.5}, "codon_usage_bias": {"TTT": 0.5}}),
            ]
            
            for endpoint, data in endpoints_to_test:
                response = await test_client.post(
                    endpoint,
                    json=data,
                    headers=admin_agent["headers"]
                )
                
                # Should not return 200 with malicious payload
                if response.status_code == 201:
                    TEST_FINDINGS["security_vulnerabilities"].append({
                        "type": "SQL Injection",
                        "endpoint": endpoint,
                        "payload": payload,
                        "severity": "critical",
                        "description": "Endpoint accepts potentially malicious SQL injection payload"
                    })
    
    @pytest.mark.asyncio
    async def test_xss_protection(self, test_client: AsyncClient, admin_agent: dict):
        """Test XSS protection"""
        xss_payloads = [
            "<script>alert('xss')</script>",
            "javascript:alert('xss')",
            "<img src=x onerror=alert('xss')>",
            "'; alert('xss'); //",
            "<iframe src='javascript:alert(\"xss\")'></iframe>"
        ]
        
        for payload in xss_payloads:
            trial_data = {
                "name": payload,
                "description": payload,
                "organism": "E. coli",
                "genome_file": "/test",
                "parameters": {
                    "window_size": 1000,
                    "min_confidence": 0.7,
                    "trait_count": 2
                },
                "created_by": admin_agent["agent"]["id"]
            }
            
            response = await test_client.post(
                "/api/v1/trials/",
                json=trial_data,
                headers=admin_agent["headers"]
            )
            
            if response.status_code == 201:
                # Check if payload is properly escaped in response
                trial = response.json()
                if payload in str(trial) and "<script>" in payload:
                    TEST_FINDINGS["security_vulnerabilities"].append({
                        "type": "XSS",
                        "endpoint": "/api/v1/trials/",
                        "payload": payload,
                        "severity": "high",
                        "description": "XSS payload not properly sanitized"
                    })
    
    @pytest.mark.asyncio
    async def test_authentication_bypass_attempts(self, test_client: AsyncClient):
        """Test authentication bypass attempts"""
        bypass_attempts = [
            # Malformed tokens
            {"Authorization": "Bearer invalid_token"},
            {"Authorization": "Bearer "},
            {"Authorization": "Basic admin:admin"},
            {"Authorization": ""},
            
            # JWT manipulation attempts
            {"Authorization": "Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxIiwiaWF0IjoxNTE2MjM5MDIyfQ.invalid"},
        ]
        
        protected_endpoint = "/api/v1/agents/me"
        
        for headers in bypass_attempts:
            response = await test_client.get(protected_endpoint, headers=headers)
            
            if response.status_code == 200:
                TEST_FINDINGS["security_vulnerabilities"].append({
                    "type": "Authentication Bypass",
                    "endpoint": protected_endpoint,
                    "headers": headers,
                    "severity": "critical",
                    "description": "Protected endpoint accessible with invalid authentication"
                })
    
    @pytest.mark.asyncio
    async def test_input_validation_edge_cases(self, test_client: AsyncClient, admin_agent: dict):
        """Test edge cases in input validation"""
        edge_cases = [
            # Extremely long strings
            {"name": "A" * 10000, "organism": "E. coli", "genome_file": "/test", "parameters": {"window_size": 1000, "min_confidence": 0.7, "trait_count": 2}, "created_by": admin_agent["agent"]["id"]},
            
            # Unicode and special characters
            {"name": "æµ‹è¯•\x00\uFEFFðŸ§¬", "organism": "E. coli", "genome_file": "/test", "parameters": {"window_size": 1000, "min_confidence": 0.7, "trait_count": 2}, "created_by": admin_agent["agent"]["id"]},
            
            # Boundary values
            {"name": "Test", "organism": "E. coli", "genome_file": "/test", "parameters": {"window_size": -1, "min_confidence": 2.0, "trait_count": -5}, "created_by": admin_agent["agent"]["id"]},
            
            # Type confusion
            {"name": ["not", "a", "string"], "organism": "E. coli", "genome_file": "/test", "parameters": {"window_size": 1000, "min_confidence": 0.7, "trait_count": 2}, "created_by": admin_agent["agent"]["id"]},
        ]
        
        for edge_case in edge_cases:
            response = await test_client.post(
                "/api/v1/trials/",
                json=edge_case,
                headers=admin_agent["headers"]
            )
            
            # Should handle edge cases gracefully
            if response.status_code not in [400, 422]:
                TEST_FINDINGS["edge_case_failures"].append({
                    "endpoint": "/api/v1/trials/",
                    "payload": edge_case,
                    "status_code": response.status_code,
                    "issue": "Edge case not handled properly"
                })


class TestCORSAndRateLimiting:
    """Test CORS configuration and rate limiting"""
    
    @pytest.mark.asyncio
    async def test_cors_headers(self, test_client: AsyncClient):
        """Test CORS headers"""
        response = await test_client.options("/api/v1/trials/")
        
        # Check for CORS headers
        expected_cors_headers = [
            "access-control-allow-origin",
            "access-control-allow-methods",
            "access-control-allow-headers"
        ]
        
        for header in expected_cors_headers:
            if header not in response.headers:
                TEST_FINDINGS["api_bugs"].append({
                    "component": "CORS",
                    "issue": f"Missing CORS header: {header}",
                    "endpoint": "/api/v1/trials/",
                    "severity": "medium"
                })
    
    @pytest.mark.asyncio
    async def test_rate_limiting(self, test_client: AsyncClient):
        """Test rate limiting behavior"""
        # Make rapid requests to check for rate limiting
        responses = []
        start_time = time.time()
        
        for i in range(APITestConfig.RATE_LIMIT_REQUESTS):
            response = await test_client.get("/health")
            responses.append(response.status_code)
            
            if response.status_code == 429:  # Rate limited
                break
        
        end_time = time.time()
        request_time = end_time - start_time
        
        # Check if any requests were rate limited
        rate_limited = any(status == 429 for status in responses)
        
        if not rate_limited and len(responses) >= APITestConfig.RATE_LIMIT_REQUESTS:
            TEST_FINDINGS["security_vulnerabilities"].append({
                "type": "Missing Rate Limiting",
                "endpoint": "/health",
                "requests_made": len(responses),
                "time_taken": request_time,
                "severity": "medium",
                "description": "No rate limiting detected on public endpoints"
            })


# Test execution and reporting functions

@pytest.mark.asyncio
async def test_generate_findings_report():
    """Generate comprehensive test findings report"""
    timestamp = datetime.now().isoformat()
    
    report = {
        "test_execution_timestamp": timestamp,
        "memory_namespace": "swarm-regression-1752301224",
        "summary": {
            "total_bugs": len(TEST_FINDINGS["api_bugs"]),
            "security_vulnerabilities": len(TEST_FINDINGS["security_vulnerabilities"]),
            "performance_issues": len(TEST_FINDINGS["performance_issues"]),
            "edge_case_failures": len(TEST_FINDINGS["edge_case_failures"])
        },
        "findings": TEST_FINDINGS,
        "test_coverage": {
            "endpoints_tested": [
                "/api/v1/agents/register",
                "/api/v1/agents/login", 
                "/api/v1/agents/me",
                "/api/v1/agents/",
                "/api/v1/trials/",
                "/api/v1/trials/{id}",
                "/api/v1/results/",
                "/api/v1/results/{id}",
                "/api/v1/progress/",
                "/ws/connect"
            ],
            "security_tests": [
                "SQL injection protection",
                "XSS protection", 
                "Authentication bypass attempts",
                "Authorization checks",
                "Input validation edge cases"
            ],
            "performance_tests": [
                "Batch operations",
                "WebSocket load testing",
                "Rate limiting",
                "Database query performance"
            ]
        },
        "recommendations": _generate_recommendations(TEST_FINDINGS)
    }
    
    # Save to memory namespace file
    report_file = f"/home/murr2k/projects/agentic/pleiotropy/tests/regression/api_test_report_{timestamp.replace(':', '-')}.json"
    
    with open(report_file, 'w') as f:
        json.dump(report, f, indent=2)
    
    print(f"\nðŸ” API Regression Test Report Generated: {report_file}")
    print(f"ðŸ“Š Summary: {report['summary']['total_bugs']} bugs, {report['summary']['security_vulnerabilities']} security issues, {report['summary']['performance_issues']} performance problems")
    
    return report


def _generate_recommendations(findings: Dict[str, List]) -> List[str]:
    """Generate recommendations based on test findings"""
    recommendations = []
    
    if findings["security_vulnerabilities"]:
        recommendations.extend([
            "Implement input sanitization for all user inputs",
            "Add rate limiting to prevent abuse",
            "Review authentication mechanisms for bypass vulnerabilities",
            "Implement proper SQL injection protection"
        ])
    
    if findings["performance_issues"]:
        recommendations.extend([
            "Optimize batch operation processing",
            "Implement connection pooling for WebSocket connections",
            "Add database query optimization",
            "Consider implementing caching for frequently accessed data"
        ])
    
    if findings["api_bugs"]:
        recommendations.extend([
            "Add comprehensive error handling",
            "Implement proper HTTP status code responses",
            "Review API endpoint functionality",
            "Add monitoring and logging for API failures"
        ])
    
    if findings["edge_case_failures"]:
        recommendations.extend([
            "Strengthen input validation",
            "Add proper boundary checking",
            "Implement graceful handling of malformed requests",
            "Add comprehensive testing for edge cases"
        ])
    
    return recommendations


if __name__ == "__main__":
    pytest.main([
        __file__,
        "-v",
        "--tb=short",
        "-x",  # Stop on first failure for debugging
        "--asyncio-mode=auto"
    ])